{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agent Chain: Chain of Responsibility Pattern in Action\n",
    "\n",
    "This notebook demonstrates how to use the **Chain of Responsibility** pattern to build intelligent AI agents that can handle different types of requests, similar to how LangChain and LangGraph create agent workflows.\n",
    "\n",
    "## Pattern Overview\n",
    "The Chain of Responsibility pattern allows a request to pass through a chain of handlers until one can process it. In AI applications, this is perfect for:\n",
    "- Multi-step reasoning\n",
    "- Specialized agent workflows  \n",
    "- Fallback mechanisms\n",
    "- Request routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chain of Responsibility pattern base class defined!\n",
      "📖 This pattern helps us create flexible agent workflows where:\n",
      "   - Each agent specializes in specific tasks\n",
      "   - Requests flow through the chain until handled\n",
      "   - Easy to add/remove/reorder agents\n",
      "   - Clean separation of concerns\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from utils.client import AIClient, MockAIClient\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "# First, let's define the Chain of Responsibility pattern base class\n",
    "class Handler(ABC):\n",
    "    \"\"\"\n",
    "    Base Handler class for Chain of Responsibility pattern\n",
    "    \n",
    "    This pattern allows passing requests along a chain of handlers. \n",
    "    Upon receiving a request, each handler decides either to process \n",
    "    the request or to pass it to the next handler in the chain.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, successor: Optional[\"Handler\"] = None):\n",
    "        \"\"\"\n",
    "        Initialize handler with optional successor\n",
    "        Args:\n",
    "            successor: Next handler in the chain\n",
    "        \"\"\"\n",
    "        self.successor = successor\n",
    "    \n",
    "    @abstractmethod\n",
    "    def handle(self, request):\n",
    "        \"\"\"\n",
    "        Handle the request or pass to successor\n",
    "        This method should be implemented by concrete handlers\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "print(\"✅ Chain of Responsibility pattern base class defined!\")\n",
    "print(\"📖 This pattern helps us create flexible agent workflows where:\")\n",
    "print(\"   - Each agent specializes in specific tasks\")  \n",
    "print(\"   - Requests flow through the chain until handled\")\n",
    "print(\"   - Easy to add/remove/reorder agents\")\n",
    "print(\"   - Clean separation of concerns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Chain of Responsibility Pattern\n",
    "\n",
    "Before diving into AI agents, let's understand what makes this pattern so powerful:\n",
    "\n",
    "### 🔗 **The Chain Concept**\n",
    "Think of it like a **customer support system**:\n",
    "1. **Level 1 Support** → handles basic questions\n",
    "2. **Level 2 Technical** → handles complex technical issues  \n",
    "3. **Level 3 Specialist** → handles very specific problems\n",
    "4. **Manager** → handles escalated cases\n",
    "\n",
    "Each level tries to help, and if they can't, they pass it up the chain!\n",
    "\n",
    "### **Why Perfect for AI Agents?**\n",
    "- **Specialization**: Each AI agent can focus on what it does best\n",
    "- **Flexibility**: Easy to add new types of agents or reorder them\n",
    "- **Fallback**: If no agent can handle something, we have a backup plan\n",
    "- **Scalability**: Chain can grow without breaking existing agents\n",
    "\n",
    "Let's build this step by step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIAgentHandler(Handler):\n",
    "    \"\"\"Base AI Agent Handler\"\"\"\n",
    "    \n",
    "    def __init__(self, successor: Optional[\"AIAgentHandler\"] = None, use_mock: bool = True):\n",
    "        super().__init__(successor)\n",
    "        self.client = MockAIClient() if use_mock else AIClient()\n",
    "        self.agent_name = self.__class__.__name__\n",
    "    \n",
    "    def handle(self, request: Dict[str, Any]) -> Optional[str]:\n",
    "        \"\"\"Handle request and return response or pass to next handler\"\"\"\n",
    "        if self.can_handle(request):\n",
    "            return self.process_request(request)\n",
    "        elif self.successor:\n",
    "            return self.successor.handle(request)\n",
    "        else:\n",
    "            return \"No handler available for this request.\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def can_handle(self, request: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Check if this handler can process the request\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def process_request(self, request: Dict[str, Any]) -> str:\n",
    "        \"\"\"Process the request and return response\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialized Agent Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeAgent(AIAgentHandler):\n",
    "    \"\"\"Handles programming and code-related queries\"\"\"\n",
    "    \n",
    "    def can_handle(self, request: Dict[str, Any]) -> bool:\n",
    "        query = request.get('query', '').lower()\n",
    "        code_keywords = ['code', 'program', 'function', 'algorithm', 'debug', 'python', 'javascript']\n",
    "        return any(keyword in query for keyword in code_keywords)\n",
    "    \n",
    "    def process_request(self, request: Dict[str, Any]) -> str:\n",
    "        prompt = f\"As a coding expert, help with: {request['query']}\"\n",
    "        response = self.client.generate_text(prompt)\n",
    "        return f\"🤖 {self.agent_name}: {response}\"\n",
    "\n",
    "\n",
    "class MathAgent(AIAgentHandler):\n",
    "    \"\"\"Handles mathematical queries and calculations\"\"\"\n",
    "    \n",
    "    def can_handle(self, request: Dict[str, Any]) -> bool:\n",
    "        query = request.get('query', '').lower()\n",
    "        math_keywords = ['calculate', 'math', 'equation', 'solve', 'formula', 'statistics']\n",
    "        return any(keyword in query for keyword in math_keywords)\n",
    "    \n",
    "    def process_request(self, request: Dict[str, Any]) -> str:\n",
    "        prompt = f\"As a math expert, solve: {request['query']}\"\n",
    "        response = self.client.generate_text(prompt)\n",
    "        return f\"📊 {self.agent_name}: {response}\"\n",
    "\n",
    "\n",
    "class GeneralAgent(AIAgentHandler):\n",
    "    \"\"\"Handles general queries that don't fit other categories\"\"\"\n",
    "    \n",
    "    def can_handle(self, request: Dict[str, Any]) -> bool:\n",
    "        return True  # Always handles as fallback\n",
    "    \n",
    "    def process_request(self, request: Dict[str, Any]) -> str:\n",
    "        prompt = f\"Please help with: {request['query']}\"\n",
    "        response = self.client.generate_text(prompt)\n",
    "        return f\"🧠 {self.agent_name}: {response}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Agent Chain\n",
    "\n",
    "Now let's create our agent chain, similar to LangChain's agent workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: mock)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: mock)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: mock)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 AI Agent Chain Created:\n",
      "CodeAgent → MathAgent → GeneralAgent\n"
     ]
    }
   ],
   "source": [
    "# Create agent chain\n",
    "general_agent = GeneralAgent(use_mock=True)\n",
    "math_agent = MathAgent(successor=general_agent, use_mock=True)\n",
    "code_agent = CodeAgent(successor=math_agent, use_mock=True)\n",
    "\n",
    "print(\"🔗 AI Agent Chain Created:\")\n",
    "print(\"CodeAgent → MathAgent → GeneralAgent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Agent Chain\n",
    "\n",
    "Let's test our agent chain with different types of queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Testing Agent Chain:\n",
      "\n",
      "Query 1 (code): Write a Python function to calculate fibonacci numbers\n",
      "Response: 🤖 CodeAgent: Mock coding response: Here's a simple Python function for your request about 'As a coding expert, help with:...'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Query 2 (math): Solve the equation: 2x + 5 = 15\n",
      "Response: 📊 MathAgent: Mock math response: The solution to your mathematical query 'As a math expert, solve: Solve...' is calculated as follows.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Query 3 (general): What is the capital of France?\n",
      "Response: 🧠 GeneralAgent: Mock general response: This is a helpful response to your query about 'Please help with: What is the ...'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Query 4 (code): Debug this Python code that has syntax errors\n",
      "Response: 🤖 CodeAgent: Mock coding response: Here's a simple Python function for your request about 'As a coding expert, help with:...'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Query 5 (math): Calculate the area of a circle with radius 5\n",
      "Response: 📊 MathAgent: Mock math response: The solution to your mathematical query 'As a math expert, solve: Calcu...' is calculated as follows.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    {\"query\": \"Write a Python function to calculate fibonacci numbers\", \"type\": \"code\"},\n",
    "    {\"query\": \"Solve the equation: 2x + 5 = 15\", \"type\": \"math\"},\n",
    "    {\"query\": \"What is the capital of France?\", \"type\": \"general\"},\n",
    "    {\"query\": \"Debug this Python code that has syntax errors\", \"type\": \"code\"},\n",
    "    {\"query\": \"Calculate the area of a circle with radius 5\", \"type\": \"math\"}\n",
    "]\n",
    "\n",
    "print(\"🚀 Testing Agent Chain:\\n\")\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"Query {i} ({query['type']}): {query['query']}\")\n",
    "    response = code_agent.handle(query)\n",
    "    print(f\"Response: {response}\\n\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Stateful Agent Chain\n",
    "\n",
    "Let's create a more sophisticated version that maintains state across requests, similar to LangGraph's state management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulAgentHandler(AIAgentHandler):\n",
    "    \"\"\"Agent with state management\"\"\"\n",
    "    \n",
    "    def __init__(self, successor: Optional[\"StatefulAgentHandler\"] = None, use_mock: bool = True):\n",
    "        super().__init__(successor, use_mock)\n",
    "        self.state = {\"processed_count\": 0, \"history\": []}\n",
    "    \n",
    "    def handle(self, request: Dict[str, Any]) -> Optional[str]:\n",
    "        # Update state\n",
    "        if self.can_handle(request):\n",
    "            self.state[\"processed_count\"] += 1\n",
    "            self.state[\"history\"].append(request[\"query\"])\n",
    "            \n",
    "            response = self.process_request(request)\n",
    "            return f\"{response} [Processed: {self.state['processed_count']} requests]\"\n",
    "        elif self.successor:\n",
    "            return self.successor.handle(request)\n",
    "        return \"No handler available.\"\n",
    "\n",
    "\n",
    "class StatefulCodeAgent(StatefulAgentHandler):\n",
    "    def can_handle(self, request: Dict[str, Any]) -> bool:\n",
    "        query = request.get('query', '').lower()\n",
    "        return 'code' in query or 'program' in query or 'python' in query\n",
    "    \n",
    "    def process_request(self, request: Dict[str, Any]) -> str:\n",
    "        return f\"💻 StatefulCodeAgent: Handling code request...\"\n",
    "\n",
    "\n",
    "class StatefulGeneralAgent(StatefulAgentHandler):\n",
    "    def can_handle(self, request: Dict[str, Any]) -> bool:\n",
    "        return True\n",
    "    \n",
    "    def process_request(self, request: Dict[str, Any]) -> str:\n",
    "        return f\"🎯 StatefulGeneralAgent: Handling general request...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: mock)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: mock)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Testing Stateful Agent Chain:\n",
      "\n",
      "Query: Write Python code for sorting\n",
      "Response: 💻 StatefulCodeAgent: Handling code request... [Processed: 1 requests]\n",
      "\n",
      "Query: What's the weather like?\n",
      "Response: 🎯 StatefulGeneralAgent: Handling general request... [Processed: 1 requests]\n",
      "\n",
      "Query: Create a function in Python\n",
      "Response: 💻 StatefulCodeAgent: Handling code request... [Processed: 2 requests]\n",
      "\n",
      "Query: Tell me a joke\n",
      "Response: 🎯 StatefulGeneralAgent: Handling general request... [Processed: 2 requests]\n",
      "\n",
      "📈 Code Agent State: {'processed_count': 2, 'history': ['Write Python code for sorting', 'Create a function in Python']}\n",
      "📈 General Agent State: {'processed_count': 2, 'history': [\"What's the weather like?\", 'Tell me a joke']}\n"
     ]
    }
   ],
   "source": [
    "# Create stateful agent chain\n",
    "stateful_general = StatefulGeneralAgent(use_mock=True)\n",
    "stateful_code = StatefulCodeAgent(successor=stateful_general, use_mock=True)\n",
    "\n",
    "print(\"🔄 Testing Stateful Agent Chain:\\n\")\n",
    "\n",
    "stateful_queries = [\n",
    "    {\"query\": \"Write Python code for sorting\"},\n",
    "    {\"query\": \"What's the weather like?\"},\n",
    "    {\"query\": \"Create a function in Python\"},\n",
    "    {\"query\": \"Tell me a joke\"}\n",
    "]\n",
    "\n",
    "for query in stateful_queries:\n",
    "    response = stateful_code.handle(query)\n",
    "    print(f\"Query: {query['query']}\")\n",
    "    print(f\"Response: {response}\\n\")\n",
    "\n",
    "print(f\"📈 Code Agent State: {stateful_code.state}\")\n",
    "print(f\"📈 General Agent State: {stateful_general.state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world Applications\n",
    "\n",
    "This pattern is particularly useful for:\n",
    "\n",
    "### 1. **LangChain-style Agent Workflows**\n",
    "- Router agents that direct queries to specialized tools\n",
    "- Multi-step reasoning chains\n",
    "- Tool selection and execution\n",
    "\n",
    "### 2. **LangGraph-inspired State Management**\n",
    "- Stateful conversations across multiple turns\n",
    "- Context preservation between agent interactions\n",
    "- Complex workflow orchestration\n",
    "\n",
    "### 3. **Production AI Systems**\n",
    "- Content moderation pipelines\n",
    "- Multi-modal processing (text → image → audio)\n",
    "- Error handling and fallback mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced 2: LangGraph SubGraph Concept\n",
    "\n",
    "Now let's explore how to create **SubGraphs** - treating entire agent chains as building blocks for larger systems. This is the core concept behind LangGraph's architecture.\n",
    "\n",
    "### 🔗 **SubGraph = Chain as a Single Unit**\n",
    "\n",
    "Think of SubGraph as **\"chains within chains\"**:\n",
    "- A SubGraph encapsulates multiple agents into one logical unit\n",
    "- The MainGraph orchestrates multiple SubGraphs\n",
    "- Each SubGraph can be reused, tested, and modified independently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-TechnicalSupport)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-DataAnalytics)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-ContentCreation)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-GeneralAssistance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Creating LangGraph-style System with SubGraphs:\n",
      "🏗️ Building LangGraph-style SubGraph Architecture...\n",
      "✅ Created 4 specialized subgraphs\n"
     ]
    }
   ],
   "source": [
    "class SubGraphHandler:\n",
    "    \"\"\"\n",
    "    SubGraph: Treat entire agent chain as a single processing unit\n",
    "    This mimics LangGraph's subgraph concept where complex workflows\n",
    "    can be encapsulated and reused as building blocks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, internal_agents: List[str], use_mock: bool = True):\n",
    "        self.name = name\n",
    "        self.internal_agents = internal_agents\n",
    "        self.client = MockAIClient(f\"subgraph-{name}\") if use_mock else AIClient(\"gemini\")\n",
    "        self.processed_requests = []\n",
    "    \n",
    "    def process(self, request: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process request through internal agent chain\"\"\"\n",
    "        print(f\"    🔸 SubGraph '{self.name}' processing...\")\n",
    "        \n",
    "        # Simulate chain processing through multiple agents\n",
    "        for i, agent in enumerate(self.internal_agents, 1):\n",
    "            print(f\"      → Step {i}: {agent} analyzing...\")\n",
    "        \n",
    "        # Generate response using the subgraph's specialized prompt\n",
    "        specialized_prompt = f\"As a {self.name} expert team, help with: {request}\"\n",
    "        response = self.client.generate_text(specialized_prompt)\n",
    "        \n",
    "        # Track processed requests\n",
    "        self.processed_requests.append(request)\n",
    "        \n",
    "        return {\n",
    "            \"subgraph\": self.name,\n",
    "            \"agents_used\": self.internal_agents,\n",
    "            \"steps_count\": len(self.internal_agents),\n",
    "            \"response\": response,\n",
    "            \"total_processed\": len(self.processed_requests)\n",
    "        }\n",
    "\n",
    "class MainGraphOrchestrator:\n",
    "    \"\"\"\n",
    "    Main Graph that orchestrates multiple SubGraphs\n",
    "    Similar to LangGraph's main workflow with embedded subgraphs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_mock: bool = True):\n",
    "        print(\"🏗️ Building LangGraph-style SubGraph Architecture...\")\n",
    "        \n",
    "        # Create specialized subgraphs - each is a complete workflow\n",
    "        self.subgraphs = {\n",
    "            \"technical\": SubGraphHandler(\n",
    "                name=\"TechnicalSupport\", \n",
    "                internal_agents=[\"CodeReviewer\", \"DebugAnalyzer\", \"ArchitecturalAdvisor\", \"TestGenerator\"],\n",
    "                use_mock=use_mock\n",
    "            ),\n",
    "            \"analytical\": SubGraphHandler(\n",
    "                name=\"DataAnalytics\", \n",
    "                internal_agents=[\"DataValidator\", \"StatisticalAnalyzer\", \"VisualizationGenerator\", \"InsightExtractor\"],\n",
    "                use_mock=use_mock\n",
    "            ),\n",
    "            \"creative\": SubGraphHandler(\n",
    "                name=\"ContentCreation\", \n",
    "                internal_agents=[\"IdeaGenerator\", \"ContentWriter\", \"StyleOptimizer\", \"QualityReviewer\"],\n",
    "                use_mock=use_mock\n",
    "            ),\n",
    "            \"general\": SubGraphHandler(\n",
    "                name=\"GeneralAssistance\", \n",
    "                internal_agents=[\"QueryClassifier\", \"InformationRetriever\", \"ResponseSynthesizer\"],\n",
    "                use_mock=use_mock\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        print(f\"✅ Created {len(self.subgraphs)} specialized subgraphs\")\n",
    "    \n",
    "    def route_request(self, request: str) -> Dict[str, Any]:\n",
    "        \"\"\"Intelligent routing to appropriate subgraph (like LangGraph's conditional edges)\"\"\"\n",
    "        request_lower = request.lower()\n",
    "        \n",
    "        # Smart routing logic\n",
    "        if any(word in request_lower for word in ['code', 'bug', 'debug', 'program', 'algorithm', 'technical']):\n",
    "            chosen_subgraph = \"technical\"\n",
    "        elif any(word in request_lower for word in ['analyze', 'data', 'calculate', 'statistics', 'chart', 'math']):\n",
    "            chosen_subgraph = \"analytical\"\n",
    "        elif any(word in request_lower for word in ['write', 'create', 'story', 'article', 'content', 'blog']):\n",
    "            chosen_subgraph = \"creative\"\n",
    "        else:\n",
    "            chosen_subgraph = \"general\"\n",
    "        \n",
    "        print(f\"  🎯 MainGraph routing to '{chosen_subgraph}' subgraph\")\n",
    "        result = self.subgraphs[chosen_subgraph].process(request)\n",
    "        \n",
    "        return {\n",
    "            \"main_graph_decision\": chosen_subgraph,\n",
    "            \"subgraph_result\": result,\n",
    "            \"total_steps\": result[\"steps_count\"] + 1  # +1 for routing step\n",
    "        }\n",
    "    \n",
    "    def get_system_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get statistics about the entire system\"\"\"\n",
    "        stats = {}\n",
    "        total_processed = 0\n",
    "        \n",
    "        for name, subgraph in self.subgraphs.items():\n",
    "            count = len(subgraph.processed_requests)\n",
    "            stats[name] = count\n",
    "            total_processed += count\n",
    "        \n",
    "        return {\n",
    "            \"subgraph_usage\": stats,\n",
    "            \"total_requests_processed\": total_processed,\n",
    "            \"most_used_subgraph\": max(stats.keys(), key=lambda k: stats[k]) if total_processed > 0 else \"none\"\n",
    "        }\n",
    "\n",
    "# Create the MainGraph system\n",
    "print(\"🚀 Creating LangGraph-style System with SubGraphs:\")\n",
    "main_system = MainGraphOrchestrator(use_mock=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-TechnicalSupport)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-BillingSupport)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-GeneralInquiry)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-ResearchTeam)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-WritingTeam)\n",
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: subgraph-ProductionTeam)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 SubGraph Flexibility Demo - Different System Configurations:\n",
      "\n",
      "System 1: Customer Support\n",
      "🏢 Building Customer Support System...\n",
      "   SubGraphs: ['technical_support', 'billing_support', 'general_inquiry']\n",
      "\\nSystem 2: Content Production\n",
      "📝 Building Content Production System...\n",
      "   SubGraphs: ['research', 'writing', 'production']\n",
      "\\n🎯 Key Insight: Same SubGraph Pattern, Different Business Logic!\n",
      "   - Reusable architecture patterns\n",
      "   - Domain-specific implementations\n",
      "   - Easy to create new system types\n",
      "\\n🚀 This demonstrates the power of the SubGraph pattern:\n",
      "   ✅ One pattern, infinite applications\n",
      "   ✅ Business logic separated from architecture\n",
      "   ✅ Rapid prototyping of complex systems\n",
      "   ✅ Perfect foundation for LangGraph-style AI workflows!\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate SubGraph Flexibility - Creating Different MainGraph Configurations\n",
    "print(\"🔧 SubGraph Flexibility Demo - Different System Configurations:\\n\")\n",
    "\n",
    "# Configuration 1: Customer Support System\n",
    "class CustomerSupportSystem(MainGraphOrchestrator):\n",
    "    def __init__(self, use_mock: bool = True):\n",
    "        print(\"🏢 Building Customer Support System...\")\n",
    "        self.subgraphs = {\n",
    "            \"technical_support\": SubGraphHandler(\n",
    "                name=\"TechnicalSupport\", \n",
    "                internal_agents=[\"IssueClassifier\", \"TroubleshootingAgent\", \"EscalationHandler\"],\n",
    "                use_mock=use_mock\n",
    "            ),\n",
    "            \"billing_support\": SubGraphHandler(\n",
    "                name=\"BillingSupport\", \n",
    "                internal_agents=[\"AccountVerifier\", \"PaymentProcessor\", \"RefundHandler\"],\n",
    "                use_mock=use_mock\n",
    "            ),\n",
    "            \"general_inquiry\": SubGraphHandler(\n",
    "                name=\"GeneralInquiry\", \n",
    "                internal_agents=[\"FAQMatcher\", \"InfoProvider\", \"FollowUpScheduler\"],\n",
    "                use_mock=use_mock\n",
    "            )\n",
    "        }\n",
    "\n",
    "# Configuration 2: Content Production System  \n",
    "class ContentProductionSystem(MainGraphOrchestrator):\n",
    "    def __init__(self, use_mock: bool = True):\n",
    "        print(\"📝 Building Content Production System...\")\n",
    "        self.subgraphs = {\n",
    "            \"research\": SubGraphHandler(\n",
    "                name=\"ResearchTeam\", \n",
    "                internal_agents=[\"TopicAnalyzer\", \"SourceGatherer\", \"FactChecker\", \"OutlineCreator\"],\n",
    "                use_mock=use_mock\n",
    "            ),\n",
    "            \"writing\": SubGraphHandler(\n",
    "                name=\"WritingTeam\", \n",
    "                internal_agents=[\"ContentWriter\", \"StyleEditor\", \"SEOOptimizer\"],\n",
    "                use_mock=use_mock\n",
    "            ),\n",
    "            \"production\": SubGraphHandler(\n",
    "                name=\"ProductionTeam\", \n",
    "                internal_agents=[\"MediaCreator\", \"QualityReviewer\", \"PublishingCoordinator\"],\n",
    "                use_mock=use_mock\n",
    "            )\n",
    "        }\n",
    "\n",
    "# Show different system configurations\n",
    "print(\"System 1: Customer Support\")\n",
    "support_system = CustomerSupportSystem(use_mock=True)\n",
    "print(f\"   SubGraphs: {list(support_system.subgraphs.keys())}\")\n",
    "\n",
    "print(\"\\\\nSystem 2: Content Production\") \n",
    "content_system = ContentProductionSystem(use_mock=True)\n",
    "print(f\"   SubGraphs: {list(content_system.subgraphs.keys())}\")\n",
    "\n",
    "print(\"\\\\n🎯 Key Insight: Same SubGraph Pattern, Different Business Logic!\")\n",
    "print(\"   - Reusable architecture patterns\")\n",
    "print(\"   - Domain-specific implementations\") \n",
    "print(\"   - Easy to create new system types\")\n",
    "\n",
    "print(\"\\\\n🚀 This demonstrates the power of the SubGraph pattern:\")\n",
    "print(\"   ✅ One pattern, infinite applications\")\n",
    "print(\"   ✅ Business logic separated from architecture\") \n",
    "print(\"   ✅ Rapid prototyping of complex systems\")\n",
    "print(\"   ✅ Perfect foundation for LangGraph-style AI workflows!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the SubGraph System\n",
    "\n",
    "Let's see how our LangGraph-style system handles different types of requests by routing them to appropriate subgraphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing LangGraph SubGraph System:\n",
      "\n",
      "📝 Request 1: Debug my Python sorting algorithm that's throwing index errors\n",
      "  🎯 MainGraph routing to 'technical' subgraph\n",
      "    🔸 SubGraph 'TechnicalSupport' processing...\n",
      "      → Step 1: CodeReviewer analyzing...\n",
      "      → Step 2: DebugAnalyzer analyzing...\n",
      "      → Step 3: ArchitecturalAdvisor analyzing...\n",
      "      → Step 4: TestGenerator analyzing...\n",
      "✅ Processed by: TechnicalSupport (4 steps)\n",
      "📄 Response: Mock coding response: Here's a simple Python function for your request about 'As a TechnicalSupport ...\n",
      "📊 This subgraph has handled: 1 requests\n",
      "------------------------------------------------------------\n",
      "📝 Request 2: Analyze sales data trends for Q4 and create visualizations\n",
      "  🎯 MainGraph routing to 'analytical' subgraph\n",
      "    🔸 SubGraph 'DataAnalytics' processing...\n",
      "      → Step 1: DataValidator analyzing...\n",
      "      → Step 2: StatisticalAnalyzer analyzing...\n",
      "      → Step 3: VisualizationGenerator analyzing...\n",
      "      → Step 4: InsightExtractor analyzing...\n",
      "✅ Processed by: DataAnalytics (4 steps)\n",
      "📄 Response: Mock general response: This is a helpful response to your query about 'As a DataAnalytics expert tea...\n",
      "📊 This subgraph has handled: 1 requests\n",
      "------------------------------------------------------------\n",
      "📝 Request 3: Write a compelling blog post about AI ethics\n",
      "  🎯 MainGraph routing to 'creative' subgraph\n",
      "    🔸 SubGraph 'ContentCreation' processing...\n",
      "      → Step 1: IdeaGenerator analyzing...\n",
      "      → Step 2: ContentWriter analyzing...\n",
      "      → Step 3: StyleOptimizer analyzing...\n",
      "      → Step 4: QualityReviewer analyzing...\n",
      "✅ Processed by: ContentCreation (4 steps)\n",
      "📄 Response: Mock general response: This is a helpful response to your query about 'As a ContentCreation expert t...\n",
      "📊 This subgraph has handled: 1 requests\n",
      "------------------------------------------------------------\n",
      "📝 Request 4: What's the best way to learn machine learning?\n",
      "  🎯 MainGraph routing to 'general' subgraph\n",
      "    🔸 SubGraph 'GeneralAssistance' processing...\n",
      "      → Step 1: QueryClassifier analyzing...\n",
      "      → Step 2: InformationRetriever analyzing...\n",
      "      → Step 3: ResponseSynthesizer analyzing...\n",
      "✅ Processed by: GeneralAssistance (3 steps)\n",
      "📄 Response: Mock general response: This is a helpful response to your query about 'As a GeneralAssistance expert...\n",
      "📊 This subgraph has handled: 1 requests\n",
      "------------------------------------------------------------\n",
      "📝 Request 5: Fix this React component that won't render properly\n",
      "  🎯 MainGraph routing to 'general' subgraph\n",
      "    🔸 SubGraph 'GeneralAssistance' processing...\n",
      "      → Step 1: QueryClassifier analyzing...\n",
      "      → Step 2: InformationRetriever analyzing...\n",
      "      → Step 3: ResponseSynthesizer analyzing...\n",
      "✅ Processed by: GeneralAssistance (3 steps)\n",
      "📄 Response: Mock general response: This is a helpful response to your query about 'As a GeneralAssistance expert...\n",
      "📊 This subgraph has handled: 2 requests\n",
      "------------------------------------------------------------\n",
      "📝 Request 6: Calculate correlation between user engagement and revenue\n",
      "  🎯 MainGraph routing to 'analytical' subgraph\n",
      "    🔸 SubGraph 'DataAnalytics' processing...\n",
      "      → Step 1: DataValidator analyzing...\n",
      "      → Step 2: StatisticalAnalyzer analyzing...\n",
      "      → Step 3: VisualizationGenerator analyzing...\n",
      "      → Step 4: InsightExtractor analyzing...\n",
      "✅ Processed by: DataAnalytics (4 steps)\n",
      "📄 Response: Mock math response: The solution to your mathematical query 'As a DataAnalytics expert team...' is c...\n",
      "📊 This subgraph has handled: 2 requests\n",
      "------------------------------------------------------------\n",
      "\n",
      "📈 System Statistics:\n",
      "Total requests processed: 6\n",
      "Most used subgraph: analytical\n",
      "\n",
      "📊 SubGraph Usage Breakdown:\n",
      "  technical: 1 requests (16.7%)\n",
      "  analytical: 2 requests (33.3%)\n",
      "  creative: 1 requests (16.7%)\n",
      "  general: 2 requests (33.3%)\n"
     ]
    }
   ],
   "source": [
    "# Test the SubGraph system with diverse requests\n",
    "subgraph_test_cases = [\n",
    "    \"Debug my Python sorting algorithm that's throwing index errors\",\n",
    "    \"Analyze sales data trends for Q4 and create visualizations\", \n",
    "    \"Write a compelling blog post about AI ethics\",\n",
    "    \"What's the best way to learn machine learning?\",\n",
    "    \"Fix this React component that won't render properly\",\n",
    "    \"Calculate correlation between user engagement and revenue\"\n",
    "]\n",
    "\n",
    "print(\"🧪 Testing LangGraph SubGraph System:\\n\")\n",
    "\n",
    "results = []\n",
    "for i, test_case in enumerate(subgraph_test_cases, 1):\n",
    "    print(f\"📝 Request {i}: {test_case}\")\n",
    "    \n",
    "    result = main_system.route_request(test_case)\n",
    "    results.append(result)\n",
    "    \n",
    "    subgraph_info = result[\"subgraph_result\"]\n",
    "    print(f\"✅ Processed by: {subgraph_info['subgraph']} ({subgraph_info['steps_count']} steps)\")\n",
    "    print(f\"📄 Response: {subgraph_info['response'][:100]}...\")\n",
    "    print(f\"📊 This subgraph has handled: {subgraph_info['total_processed']} requests\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Show system statistics\n",
    "print(f\"\\n📈 System Statistics:\")\n",
    "stats = main_system.get_system_stats()\n",
    "print(f\"Total requests processed: {stats['total_requests_processed']}\")\n",
    "print(f\"Most used subgraph: {stats['most_used_subgraph']}\")\n",
    "\n",
    "print(f\"\\n📊 SubGraph Usage Breakdown:\")\n",
    "for subgraph_name, count in stats['subgraph_usage'].items():\n",
    "    percentage = (count / stats['total_requests_processed'] * 100) if stats['total_requests_processed'] > 0 else 0\n",
    "    print(f\"  {subgraph_name}: {count} requests ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SubGraph Architecture Benefits\n",
    "\n",
    "### 🏗️ **LangGraph SubGraph Pattern Advantages:**\n",
    "\n",
    "#### **1. Hierarchical Composition**\n",
    "```\n",
    "MainGraph (Level 0)\n",
    "├── TechnicalSupport SubGraph (Level 1)\n",
    "│   ├── CodeReviewer → DebugAnalyzer → ArchitecturalAdvisor → TestGenerator\n",
    "├── DataAnalytics SubGraph (Level 1)  \n",
    "│   ├── DataValidator → StatisticalAnalyzer → VisualizationGenerator → InsightExtractor\n",
    "└── ContentCreation SubGraph (Level 1)\n",
    "    ├── IdeaGenerator → ContentWriter → StyleOptimizer → QualityReviewer\n",
    "```\n",
    "\n",
    "#### **2. Real-World Parallel**\n",
    "Think of SubGraphs like **specialized departments** in a company:\n",
    "- **IT Department** (TechnicalSupport SubGraph) → handles all tech issues\n",
    "- **Data Science Team** (DataAnalytics SubGraph) → handles all analytical work  \n",
    "- **Marketing Team** (ContentCreation SubGraph) → handles all creative content\n",
    "- **Customer Service** (GeneralAssistance SubGraph) → handles everything else\n",
    "\n",
    "#### **3. Key Benefits:**\n",
    "- **🔹 Encapsulation**: Each subgraph is self-contained with its own workflow\n",
    "- **🔹 Reusability**: Subgraphs can be used in multiple main graphs\n",
    "- **🔹 Testability**: Each subgraph can be tested independently\n",
    "- **🔹 Maintainability**: Changes to one subgraph don't affect others\n",
    "- **🔹 Scalability**: Add new subgraphs without modifying existing code\n",
    "- **🔹 Performance**: Parallel processing of different subgraphs\n",
    "\n",
    "### 🔄 **Pattern Hierarchy We've Built:**\n",
    "\n",
    "1. **Chain of Responsibility** (Level 1) → Simple agent chains\n",
    "2. **SubGraph Pattern** (Level 2) → Multiple chains as building blocks  \n",
    "3. **MainGraph Orchestration** (Level 3) → System-level coordination\n",
    "\n",
    "This is exactly how **LangGraph** structures complex AI workflows! 🎯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3-ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Schema Factory + Pydantic Validation Workshop\n",
    "\n",
    "## The Challenge: Taming Wild LLM Outputs \n",
    "\n",
    "**Problem**: LLMs are creative but unpredictable. Ask for structured data, get creative chaos.\n",
    "\n",
    "**Solution**: **Factory Pattern** + **JSON Schema** + **Pydantic** = Structured AI Magic\n",
    "\n",
    "### Function Call vs Custom Schema\n",
    "\n",
    "**Modern LLM APIs** (OpenAI, Gemini, Anthropic) offer **Function Calling** for structured outputs:\n",
    "- ✅ **Built-in**: Native JSON schema validation at API level\n",
    "- ✅ **Convenient**: Direct integration with provider-specific tools  \n",
    "- ❌ **Vendor Lock-in**: Tied to specific providers and their implementations\n",
    "- ❌ **Limited Control**: Validation happens on their servers, not yours\n",
    "- ❌ **Cost Impact**: Every validation requires an API call\n",
    "\n",
    "**Our Custom Approach** offers deeper control and flexibility:\n",
    "-  **Provider Independence**: Works with ANY LLM (OpenAI, Gemini, Anthropic, local models)\n",
    "-  **Data Security**: Local validation, no sensitive business data sent to third parties\n",
    "-  **Business Logic**: Custom validation rules beyond basic JSON schema\n",
    "-  **Cost Control**: Validation happens locally, saving API costs\n",
    "-  **Analytics**: Track validation patterns and data quality metrics locally\n",
    "\n",
    "### The Magic Trio:\n",
    "-  **JSON Schema Factory**: Templates that guide LLM output (like Function Call schemas)\n",
    "-  **LLM Provider**: Generates data following our templates (any provider)\n",
    "-  **Pydantic**: Validates and cleans results with business logic\n",
    "\n",
    "### Real-World Impact:\n",
    "Think of it like this: **Function Calls** are like ordering from a fixed restaurant menu, while **our approach** is like having your own kitchen with any chef and your own quality standards!\n",
    "\n",
    "**Note**: This tutorial shows the foundational approach. While Gemini has native function calling, understanding this pattern gives you provider independence and deeper control.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Schema Templates - The Recipe Cards\n",
    "\n",
    "**Setup Phase**: Import essential libraries for our schema factory pattern. We'll use Pydantic for validation, \n",
    "standard typing for type hints, and our custom AI client to demonstrate real LLM integration. This foundational \n",
    "setup enables us to build provider-independent structured data generation systems.\n",
    "\n",
    "These are the \"instruction manuals\" we give to LLMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ready to build structured AI systems!\n",
      "📋 Available AI providers: ['gemini', 'gemini-pro', 'openai', 'openai-gpt3', 'anthropic']\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Type\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from enum import Enum\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import our multi-provider AI client\n",
    "sys.path.append('..')\n",
    "from utils.client import AIClient, MockAIClient\n",
    "\n",
    "print(\"🚀 Ready to build structured AI systems!\")\n",
    "print(f\"📋 Available AI providers: {AIClient.get_available_providers()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schema Templates - The Recipe Cards**: These JSON schemas serve as instruction manuals for LLMs, similar to \n",
    "OpenAI's function calling schemas but provider-independent. Each schema defines the exact structure we want, \n",
    "making LLM outputs predictable and consistent across different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Schema templates ready!\n",
      "📊 Schema types: Product, User, Task\n",
      "🎯 Each schema guides LLMs like Function Call schemas\n"
     ]
    }
   ],
   "source": [
    "# 🏪 Product Schema - for e-commerce applications\n",
    "PRODUCT_SCHEMA = {\n",
    "    \"name\": \"string - product title\",\n",
    "    \"price\": \"number - price in USD\", \n",
    "    \"tags\": [\"string\", \"string\", \"...\"],\n",
    "    \"specs\": {\n",
    "        \"weight\": \"string - with units\",\n",
    "        \"color\": \"string - primary color\"\n",
    "    },\n",
    "    \"description\": \"string - brief product description\"\n",
    "}\n",
    "\n",
    "# 👤 User Schema - for social/professional applications  \n",
    "USER_SCHEMA = {\n",
    "    \"username\": \"string - 3-20 characters\",\n",
    "    \"age\": \"integer - between 13-120\",\n",
    "    \"email\": \"string - valid email format\",\n",
    "    \"skills\": [\"string\", \"string\", \"...\"],\n",
    "    \"location\": \"string - city, country format\"\n",
    "}\n",
    "\n",
    "# 📝 Task Schema - for productivity applications\n",
    "TASK_SCHEMA = {\n",
    "    \"title\": \"string - task description\",\n",
    "    \"priority\": \"string - high|medium|low\",\n",
    "    \"estimated_hours\": \"number - time estimate\",\n",
    "    \"categories\": [\"string\", \"...\"],\n",
    "    \"dependencies\": [\"string\", \"...\"]\n",
    "}\n",
    "\n",
    "print(\"📋 Schema templates ready!\")\n",
    "print(f\"📊 Schema types: Product, User, Task\")\n",
    "print(f\"🎯 Each schema guides LLMs like Function Call schemas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Factory Pattern - The Smart Chef Selector\n",
    "\n",
    "**Factory Pattern Implementation**: The Factory Pattern dynamically selects appropriate schemas based on data type,\n",
    "similar to how function calling chooses the right function. This abstraction layer makes our system extensible and \n",
    "maintainable, allowing easy addition of new schema types without modifying existing code.\n",
    "\n",
    "Different tasks need different templates. Factory Pattern chooses the right one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏭 Factory created!\n",
      "Available types: ['product', 'user']\n",
      "\n",
      "📝 Sample prompt preview: \n",
      "Generate JSON data for: Gaming laptop\n",
      "\n",
      "REQUIRED FORMAT:\n",
      "{\n",
      "  \"name\": \"string - product title\",\n",
      "  \"pr...\n"
     ]
    }
   ],
   "source": [
    "class SchemaType(Enum):\n",
    "    PRODUCT = \"product\"\n",
    "    USER = \"user\"\n",
    "\n",
    "class JSONSchemaFactory:\n",
    "    \"\"\"🏭 Factory Pattern: Smart schema selection\"\"\"\n",
    "    \n",
    "    _schemas = {\n",
    "        SchemaType.PRODUCT: PRODUCT_SCHEMA,\n",
    "        SchemaType.USER: USER_SCHEMA\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def get_llm_prompt(cls, schema_type: SchemaType, task: str) -> str:\n",
    "        \"\"\"🎯 Create LLM prompt with schema guidance\"\"\"\n",
    "        schema = cls._schemas[schema_type]\n",
    "        return f\"\"\"\n",
    "Generate JSON data for: {task}\n",
    "\n",
    "REQUIRED FORMAT:\n",
    "{json.dumps(schema, indent=2)}\n",
    "\n",
    "Return ONLY valid JSON, no extra text.\n",
    "\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def list_types(cls) -> List[str]:\n",
    "        return [t.value for t in cls._schemas.keys()]\n",
    "\n",
    "# Demo: Create prompts for different scenarios\n",
    "factory = JSONSchemaFactory()\n",
    "\n",
    "print(\"🏭 Factory created!\")\n",
    "print(f\"Available types: {factory.list_types()}\")\n",
    "\n",
    "# Example: E-commerce product generation\n",
    "prompt = factory.get_llm_prompt(SchemaType.PRODUCT, \"Gaming laptop\")\n",
    "print(f\"\\n📝 Sample prompt preview: {prompt[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Pydantic Models - The Quality Inspector\n",
    "\n",
    "**Pydantic Validation Models**: These models act as quality inspectors, ensuring LLM outputs meet our business \n",
    "requirements. Unlike basic JSON validation in function calls, Pydantic provides deep validation with custom rules, \n",
    "type coercion, and detailed error reporting for robust data processing.\n",
    "\n",
    "These ensure LLM outputs meet our standards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation models ready!\n",
      "🛡️  Built-in validation rules:\n",
      "   • Product price must be > 0\n",
      "   • User age: 13-120 years\n",
      "   • Email format checking\n",
      "   • Username length: 3-20 chars\n"
     ]
    }
   ],
   "source": [
    "class ProductSpecs(BaseModel):\n",
    "    weight: str\n",
    "    color: str\n",
    "\n",
    "class Product(BaseModel):\n",
    "    name: str = Field(min_length=1, description=\"Product name\")\n",
    "    price: float = Field(gt=0, description=\"Must be positive\")\n",
    "    tags: List[str] = Field(min_items=1, description=\"At least one tag\")\n",
    "    specs: ProductSpecs\n",
    "\n",
    "class User(BaseModel):\n",
    "    username: str = Field(min_length=3, max_length=20)\n",
    "    age: int = Field(ge=13, le=120, description=\"Realistic age range\")\n",
    "    email: str = Field(pattern=r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n",
    "    skills: List[str] = Field(default_factory=list)\n",
    "\n",
    "print(\"✅ Validation models ready!\")\n",
    "print(\"🛡️  Built-in validation rules:\")\n",
    "print(\"   • Product price must be > 0\")\n",
    "print(\"   • User age: 13-120 years\")\n",
    "print(\"   • Email format checking\")\n",
    "print(\"   • Username length: 3-20 chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Validation Factory - Automatic Quality Control\n",
    "\n",
    "**Validation Factory - Quality Control Hub**: This factory maps schema types to their corresponding validators, \n",
    "creating a clean abstraction layer. It provides automatic validation routing and consistent error handling across \n",
    "all data types, making the system maintainable and extensible.\n",
    "\n",
    "Connects schema types to their validators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Validation Factory ready!\n",
      "Now we can automatically validate any LLM output!\n"
     ]
    }
   ],
   "source": [
    "class ValidationFactory:\n",
    "    \"\"\"🎯 Maps schema types to validators\"\"\"\n",
    "    \n",
    "    _validators = {\n",
    "        SchemaType.PRODUCT: Product,\n",
    "        SchemaType.USER: User\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def validate(cls, schema_type: SchemaType, raw_data: Dict) -> BaseModel:\n",
    "        \"\"\"🔍 Validate LLM output\"\"\"\n",
    "        validator = cls._validators[schema_type]\n",
    "        return validator(**raw_data)  # Pydantic magic happens here!\n",
    "\n",
    "print(\"🎯 Validation Factory ready!\")\n",
    "print(\"Now we can automatically validate any LLM output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: The Complete Pipeline - Magic in Action ✨\n",
    "\n",
    "Watch the full workflow: Schema → LLM Simulation → Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GAMING LAPTOP PIPELINE ===\n",
      "📝 Generated prompt (375 chars)\n",
      "🤖 LLM Output: {\n",
      "  \"name\": \"Gaming Laptop Pro\",\n",
      "  \"price\": 1299.99,\n",
      "  \"tags\": [\n",
      "    \"gaming\",\n",
      "    \"laptop\",\n",
      "    \"high-performance\"\n",
      "  ],\n",
      "  \"specs\": {\n",
      "    \"weight\": \"2.5kg\",\n",
      "    \"color\": \"black\"\n",
      "  }\n",
      "}\n",
      "✅ VALIDATION SUCCESS!\n",
      "📊 Result type: Product\n",
      "🎯 Clean data ready for your app!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Product(name='Gaming Laptop Pro', price=1299.99, tags=['gaming', 'laptop', 'high-performance'], specs=ProductSpecs(weight='2.5kg', color='black'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def demonstrate_pipeline(schema_type: SchemaType, task: str, mock_llm_output: Dict):\n",
    "    \"\"\"🎬 Full demonstration of the pipeline\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== {task.upper()} PIPELINE ===\")\n",
    "    \n",
    "    # Step 1: Generate LLM prompt\n",
    "    prompt = JSONSchemaFactory.get_llm_prompt(schema_type, task)\n",
    "    print(f\"📝 Generated prompt ({len(prompt)} chars)\")\n",
    "    \n",
    "    # Step 2: Simulate LLM response\n",
    "    print(f\"🤖 LLM Output: {json.dumps(mock_llm_output, indent=2)}\")\n",
    "    \n",
    "    # Step 3: Validate with Pydantic\n",
    "    try:\n",
    "        validated = ValidationFactory.validate(schema_type, mock_llm_output)\n",
    "        print(f\"✅ VALIDATION SUCCESS!\")\n",
    "        print(f\"📊 Result type: {type(validated).__name__}\")\n",
    "        print(f\"🎯 Clean data ready for your app!\")\n",
    "        return validated\n",
    "    except ValidationError as e:\n",
    "        print(f\"❌ VALIDATION FAILED:\")\n",
    "        for error in e.errors():\n",
    "            print(f\"   • {error['loc'][0]}: {error['msg']}\")\n",
    "        return None\n",
    "\n",
    "# Demo 1: Perfect product data\n",
    "good_product = {\n",
    "    \"name\": \"Gaming Laptop Pro\",\n",
    "    \"price\": 1299.99,\n",
    "    \"tags\": [\"gaming\", \"laptop\", \"high-performance\"],\n",
    "    \"specs\": {\"weight\": \"2.5kg\", \"color\": \"black\"}\n",
    "}\n",
    "\n",
    "demonstrate_pipeline(SchemaType.PRODUCT, \"Gaming laptop\", good_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real LLM Integration**: Now we integrate with actual LLM providers using our multi-provider client. This \n",
    "demonstrates how our schema factory works with real AI services like Gemini, while maintaining provider independence. \n",
    "The mock client provides a fallback for testing without API costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.client:🧪 MockAIClient initialized for testing (provider: mock)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Testing Real LLM Integration Pipeline:\n",
      "\\n=== GAMING LAPTOP FOR PROFESSIONALS - MOCK PIPELINE ===\n",
      "📝 Generated structured prompt (393 chars)\n",
      "🧪 Using mock client for demo...\n",
      "📤 LLM Response received (105 chars)\n",
      "⚠️  JSON extraction failed, using mock data\n",
      "❌ Pipeline error: TASK\n",
      "\\n=== SOFTWARE DEVELOPER PROFILE - REAL API PIPELINE ===\n",
      "📝 Generated structured prompt (338 chars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.client:✅ gemini client initialized (model: gemini-2.5-flash)\n",
      "INFO:utils.client:🗑️ Chat history cleared\n",
      "INFO:utils.client:🗑️ Chat history cleared\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Using real Gemini API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/openai/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 LLM Response received (258 chars)\n",
      "🔍 Extracted data: {\n",
      "  \"username\": \"coder_xyz_123\",\n",
      "  \"age\": 32,\n",
      "  \"email\": \"jane.doe@example.com\",\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"JavaScript\",\n",
      "    \"React\",\n",
      "    \"Node.js\",\n",
      "    \"Docker\",\n",
      "    \"AWS\",\n",
      "    \"MongoDB\",\n",
      "    \"Git\"\n",
      "  ],\n",
      "  \"location\": \"San Francisco, USA\"\n",
      "}\n",
      "✅ VALIDATION SUCCESS!\n",
      "📊 Result type: User\n",
      "🎯 Clean, validated data ready for your application!\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_real_llm_pipeline(schema_type: SchemaType, task: str, use_real_api: bool = False):\n",
    "    \"\"\"\n",
    "    🎬 Complete pipeline with real LLM integration\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\\\n=== {task.upper()} - {'REAL API' if use_real_api else 'MOCK'} PIPELINE ===\")\n",
    "    \n",
    "    # Step 1: Generate LLM prompt using our factory\n",
    "    prompt = JSONSchemaFactory.get_llm_prompt(schema_type, task)\n",
    "    print(f\"📝 Generated structured prompt ({len(prompt)} chars)\")\n",
    "    \n",
    "    # Step 2: Get LLM response (real or mock)\n",
    "    try:\n",
    "        if use_real_api:\n",
    "            # Try real Gemini API (falls back to mock if no API key)\n",
    "            try:\n",
    "                client = AIClient(\"gemini\")\n",
    "                print(f\"🤖 Using real Gemini API...\")\n",
    "                llm_response = client.simple_query(prompt)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  API unavailable ({str(e)[:50]}...), using mock\")\n",
    "                client = MockAIClient(\"gemini-mock\")\n",
    "                llm_response = client.simple_query(prompt)\n",
    "        else:\n",
    "            client = MockAIClient(\"mock\")\n",
    "            print(f\"🧪 Using mock client for demo...\")\n",
    "            llm_response = client.simple_query(prompt)\n",
    "        \n",
    "        print(f\"📤 LLM Response received ({len(llm_response)} chars)\")\n",
    "        \n",
    "        # Step 3: Extract JSON from response (LLMs sometimes add extra text)\n",
    "        try:\n",
    "            # Try to find JSON in the response\n",
    "            start_idx = llm_response.find('{')\n",
    "            end_idx = llm_response.rfind('}') + 1\n",
    "            if start_idx != -1 and end_idx != 0:\n",
    "                json_str = llm_response[start_idx:end_idx]\n",
    "                llm_data = json.loads(json_str)\n",
    "            else:\n",
    "                # Fallback: use mock data if JSON extraction fails\n",
    "                print(\"⚠️  JSON extraction failed, using mock data\")\n",
    "                llm_data = get_mock_data(schema_type)\n",
    "                \n",
    "        except json.JSONDecodeError:\n",
    "            print(\"⚠️  JSON parsing failed, using mock data\")\n",
    "            llm_data = get_mock_data(schema_type)\n",
    "        \n",
    "        print(f\"🔍 Extracted data: {json.dumps(llm_data, indent=2)}\")\n",
    "        \n",
    "        # Step 4: Validate with Pydantic\n",
    "        try:\n",
    "            validated = ValidationFactory.validate(schema_type, llm_data)\n",
    "            print(f\"✅ VALIDATION SUCCESS!\")\n",
    "            print(f\"📊 Result type: {type(validated).__name__}\")\n",
    "            print(f\"🎯 Clean, validated data ready for your application!\")\n",
    "            return validated\n",
    "            \n",
    "        except ValidationError:\n",
    "            print(f\"💡 Validation failed - this shows our quality control working!\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Pipeline error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_mock_data(schema_type: SchemaType) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate realistic mock data for demos\n",
    "    \"\"\"\n",
    "    mock_data = {\n",
    "        SchemaType.PRODUCT: {\n",
    "            \"name\": \"Professional Gaming Laptop X1\",\n",
    "            \"price\": 1899.99,\n",
    "            \"tags\": [\"gaming\", \"laptop\", \"professional\", \"high-performance\"],\n",
    "            \"specs\": {\"weight\": \"2.8kg\", \"color\": \"matte black\"},\n",
    "            \"description\": \"High-performance gaming laptop designed for professional esports and content creation.\"\n",
    "        },\n",
    "        SchemaType.USER: {\n",
    "            \"username\": \"alex_dev\",\n",
    "            \"age\": 28,\n",
    "            \"email\": \"alex.developer@example.com\",\n",
    "            \"skills\": [\"Python\", \"React\", \"Machine Learning\", \"Docker\"],\n",
    "            \"location\": \"San Francisco, USA\"\n",
    "        },\n",
    "        SchemaType.TASK: {\n",
    "            \"title\": \"Implement user authentication system\",\n",
    "            \"priority\": \"high\",\n",
    "            \"estimated_hours\": 24.5,\n",
    "            \"categories\": [\"backend\", \"security\"],\n",
    "            \"dependencies\": [\"database_setup\", \"user_model\"]\n",
    "        }\n",
    "    }\n",
    "    return mock_data[schema_type]\n",
    "\n",
    "# Demo with different scenarios\n",
    "print(\"🚀 Testing Real LLM Integration Pipeline:\")\n",
    "\n",
    "# Test 1: Product with mock\n",
    "result1 = demonstrate_real_llm_pipeline(SchemaType.PRODUCT, \"Gaming laptop for professionals\", False)\n",
    "\n",
    "# Test 2: User with real API (if available)\n",
    "result2 = demonstrate_real_llm_pipeline(SchemaType.USER, \"Software developer profile\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Error Handling - When LLMs Misbehave\n",
    "\n",
    "**Error Handling & Quality Control**: This section demonstrates how our validation system catches various data \n",
    "quality issues that LLMs might produce. Unlike basic function calling validation, our system provides detailed \n",
    "error analysis and business rule enforcement, showing the value of local validation control.\n",
    "\n",
    "See how Pydantic catches problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TESTING ERROR HANDLING:\n",
      "\n",
      "=== SOCIAL MEDIA USER PIPELINE ===\n",
      "📝 Generated prompt (329 chars)\n",
      "🤖 LLM Output: {\n",
      "  \"username\": \"jo\",\n",
      "  \"age\": 150,\n",
      "  \"email\": \"not-an-email\",\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"AI\"\n",
      "  ]\n",
      "}\n",
      "❌ VALIDATION FAILED:\n",
      "   • username: String should have at least 3 characters\n",
      "   • age: Input should be less than or equal to 120\n",
      "   • email: String should match pattern '^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
      "\n",
      "💡 Key Insight: Pydantic catches ALL validation issues!\n",
      "   This prevents bad data from entering your system.\n"
     ]
    }
   ],
   "source": [
    "# Demo 2: Problematic user data (multiple errors)\n",
    "bad_user = {\n",
    "    \"username\": \"jo\",           # ❌ Too short (min 3 chars)\n",
    "    \"age\": 150,                # ❌ Too old (max 120)\n",
    "    \"email\": \"not-an-email\",   # ❌ Invalid format\n",
    "    \"skills\": [\"Python\", \"AI\"] # ✅ This part is fine\n",
    "}\n",
    "\n",
    "print(\"🧪 TESTING ERROR HANDLING:\")\n",
    "demonstrate_pipeline(SchemaType.USER, \"Social media user\", bad_user)\n",
    "\n",
    "print(\"\\n💡 Key Insight: Pydantic catches ALL validation issues!\")\n",
    "print(\"   This prevents bad data from entering your system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Real-World Application\n",
    "\n",
    "**Production-Ready Service**: This final implementation showcases a complete, production-ready data generation \n",
    "service that combines all our patterns. It demonstrates error recovery, logging, and how to build reliable AI \n",
    "systems that can handle real-world complexity and edge cases gracefully.\n",
    "\n",
    "Complete example: Building a data generation service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDataService:\n",
    "    \"\"\"🏢 Production-ready service using our patterns\"\"\"\n",
    "    \n",
    "    def generate_structured_data(self, data_type: str, description: str) -> Dict:\n",
    "        \"\"\"🎯 Main service method\"\"\"\n",
    "        \n",
    "        # Convert string to enum\n",
    "        schema_type = SchemaType(data_type)\n",
    "        \n",
    "        # Generate prompt\n",
    "        prompt = JSONSchemaFactory.get_llm_prompt(schema_type, description)\n",
    "        \n",
    "        # In real app: send prompt to LLM API here\n",
    "        # For demo: use mock data\n",
    "        mock_responses = {\n",
    "            SchemaType.PRODUCT: {\n",
    "                \"name\": \"Smart Watch X1\",\n",
    "                \"price\": 299.0,\n",
    "                \"tags\": [\"wearable\", \"fitness\", \"smart\"],\n",
    "                \"specs\": {\"weight\": \"45g\", \"color\": \"silver\"}\n",
    "            },\n",
    "            SchemaType.USER: {\n",
    "                \"username\": \"alice_dev\",\n",
    "                \"age\": 28,\n",
    "                \"email\": \"alice@example.com\",\n",
    "                \"skills\": [\"Python\", \"React\", \"Machine Learning\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        llm_output = mock_responses[schema_type]\n",
    "        \n",
    "        # Validate output\n",
    "        try:\n",
    "            validated_data = ValidationFactory.validate(schema_type, llm_output)\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"data\": validated_data.dict(),\n",
    "                \"message\": \"Data generated and validated successfully!\"\n",
    "            }\n",
    "        except ValidationError as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"errors\": [str(err) for err in e.errors()],\n",
    "                \"message\": \"Validation failed\"\n",
    "            }\n",
    "\n",
    "# Test the service\n",
    "service = AIDataService()\n",
    "\n",
    "print(\"🏢 AI Data Service Demo:\")\n",
    "print(\"\\n1. Product Generation:\")\n",
    "result1 = service.generate_structured_data(\"product\", \"Fitness smartwatch\")\n",
    "print(f\"   Success: {result1['success']}\")\n",
    "print(f\"   Product: {result1['data']['name']} - ${result1['data']['price']}\")\n",
    "\n",
    "print(\"\\n2. User Generation:\")\n",
    "result2 = service.generate_structured_data(\"user\", \"Software developer profile\")\n",
    "print(f\"   Success: {result2['success']}\")\n",
    "print(f\"   User: {result2['data']['username']} ({result2['data']['age']} years old)\")\n",
    "print(f\"   Skills: {', '.join(result2['data']['skills'][:2])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve learned how to use the Factory Pattern to dynamically select the right schema based on your data type. JSON Schemas help guide language models to produce consistent and structured output. With Pydantic, you can automatically validate and clean the data, catching errors early. This creates a smooth, reliable pipeline from prompt to validated result.\n",
    "\n",
    "This approach is especially useful for:\n",
    "\n",
    "* Managing and generating structured content\n",
    "* Converting unstructured data into clean formats\n",
    "* Ensuring consistent API responses\n",
    "* Automatically creating valid test data\n",
    "\n",
    "Some tips to keep in mind:\n",
    "\n",
    "* Start with simple schemas and add complexity gradually\n",
    "* Always validate LLM output before using it\n",
    "* Keep track of schema versions over time\n",
    "* Have fallback plans for handling errors\n",
    "\n",
    "By mastering this pattern, you’re building AI systems that are predictable, safe, scalable, and easy to maintain!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

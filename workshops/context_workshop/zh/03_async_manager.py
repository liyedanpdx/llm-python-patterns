"""
âš¡ 03. å¼‚æ­¥ Context Manager

å¼‚æ­¥ Context Manager é€‚ç”¨äºéœ€è¦å¼‚æ­¥èµ„æºç®¡ç†çš„åœºæ™¯ï¼Œå¦‚ï¼š
- GPU èµ„æºæ± ç®¡ç†
- å¼‚æ­¥ç½‘ç»œè¿æ¥
- å¹¶å‘ä»»åŠ¡åè°ƒ

æ ¸å¿ƒï¼šä½¿ç”¨ @asynccontextmanager è£…é¥°å™¨å’Œ async with è¯­å¥
"""

import asyncio
from contextlib import asynccontextmanager

@asynccontextmanager
async def gpu_resource(gpu_id):
    """GPU èµ„æºç®¡ç†å™¨"""
    print(f"ğŸ”§ åˆ†é… GPU-{gpu_id}")
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¼‚æ­¥èµ„æºåˆ†é…
    try:
        yield f"GPU-{gpu_id}"
    finally:
        print(f"ğŸ”§ é‡Šæ”¾ GPU-{gpu_id}")
        await asyncio.sleep(0.05)  # æ¨¡æ‹Ÿå¼‚æ­¥æ¸…ç†

@asynccontextmanager
async def async_llm_session(session_id):
    """å¼‚æ­¥ LLM ä¼šè¯ç®¡ç†å™¨"""
    print(f"ğŸš€ å¼‚æ­¥å¯åŠ¨: {session_id}")
    session = {"id": session_id, "tasks": []}
    try:
        yield session
        print(f"âœ… å¼‚æ­¥å®Œæˆ: {session_id}")
    finally:
        print(f"ğŸ“Š å¤„ç†äº† {len(session['tasks'])} ä¸ªä»»åŠ¡")

async def process_llm_query(session, query):
    """æ¨¡æ‹Ÿå¼‚æ­¥ LLM æŸ¥è¯¢å¤„ç†"""
    session["tasks"].append(query)
    print(f"   ğŸ”„ å¤„ç†: {query}")
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†æ—¶é—´
    return f"å›å¤: {query}"

async def main():
    print("âš¡ å¼‚æ­¥ Context Manager æ¼”ç¤º\n")
    
    # 1. GPU èµ„æºç®¡ç†
    async with gpu_resource("A100") as gpu:
        print(f"   ä½¿ç”¨ {gpu} è¿›è¡Œè®¡ç®—")
        await asyncio.sleep(0.05)
    
    # 2. å¼‚æ­¥ä¼šè¯å¤„ç†
    async with async_llm_session("async-chat") as session:
        tasks = [
            process_llm_query(session, "æŸ¥è¯¢A"),
            process_llm_query(session, "æŸ¥è¯¢B"),
            process_llm_query(session, "æŸ¥è¯¢C")
        ]
        results = await asyncio.gather(*tasks)
        print(f"   ğŸ“ˆ å¹¶å‘ç»“æœ: {len(results)} ä¸ª")
    
    print("\nâœ… å…³é”®è¦ç‚¹ï¼šasync with ç®¡ç†å¼‚æ­¥èµ„æºï¼Œæ”¯æŒå¹¶å‘å¤„ç†")

if __name__ == "__main__":
    asyncio.run(main())